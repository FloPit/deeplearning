{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"Remaining Useful Life Estimation in Prognostics Using Deep Convolution Neural Networks\" by Xiang Li et al.\n",
    "\n",
    "This document reproduces the implementation of a Deep Convolutional Network  by Xiang Li et al. applied to the NASA \"CMAPSS\" dataset. This implementation has been done in Keras.\n",
    "\n",
    "Copyright (c) by Manuel Arias, Christian Schneebeli and Lukas R. Peter 2017-12-01."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before jumping into the problem, let's run the cell below to load the required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from keras import layers\n",
    "from keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D\n",
    "from keras.layers import Dropout\n",
    "from keras.models import Model\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras import optimizers\n",
    "from IPython.display import SVG, clear_output\n",
    "from keras.utils import plot_model\n",
    "from os import path\n",
    "\n",
    "import keras.callbacks\n",
    "import keras.backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1  \"CMAPSS\" Dataset\n",
    "\n",
    "The proposed method is evaluated on a prognostic benchmarking problem, i.e. NASA’s turbofan engine degradation problem [30, 41]. This popular dataset contains simulated data produced by a model-based simulation program, i.e. Commercial Modular\n",
    "Aero-Propulsion System Simulation (C-MAPSS), which was developed by NASA. The CMAPSS dataset includes 4 sub-datasets that are composed of multi-variate temporal data obtained from 21 sensors. Each sub-dataset contains one training set and one test set. The training datasets include run-to-failure sensor records of multiple aero-engines collected under different operational conditions and fault modes. Each engine unit starts with different degrees of initial wear and manufacturing variation that is unknown and considered to be healthy. As time progresses, the engine units begin to degrade until they reach the system failures, i.e. the last data entry corresponds to the time cycle that the engine unit is declared\n",
    "unhealthy. On the other hand, the sensor records in the testing datasets terminate at some time before system failure, and the goal of this task is to estimate the remaining useful life of each engine in the test dataset. For verification, the actual RUL value for the testing engine units are also provided. In this study, a comprehensive evaluation of the proposed method is carried out on all the four sub-datasets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Details of the \"CMAPSS\" dataset**\n",
    "- Training: 17731 inputs from 100 engine trajectories. It uses a sliding time window of 30 time stamps. \n",
    "- Test: 100 points from 100 engine trajectories. It takes the last available 30 time stamps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1  Data Pre-processing\n",
    "\n",
    "In the training process, all the available engine measurement data points are used as the training samples, and each data point is associated with its RUL label as the target. A piecewise linear degradation model [5] is used to obtain the RUL label with respect to each training sample. During testing, the one data point corresponding with the last recorded\n",
    "cycle for each engine unit is generally used as the testing sample. The actual RUL of the testing samples are provided in the dataset.\n",
    "\n",
    "The multi-variate temporal data in the C-MAPSS dataset contains engine unit measurements from 21 sensors [30]. However, some sensor readings have constant outputs in the engine’s lifetime and they do not provide valuable information for RUL estimation. Therefore, 14 sensor measurements out of the total 21 sensors are used as the raw input features as did in\n",
    "the literature [5, 29], whose indices are 2, 3, 4, 7, 8, 9, 11, 12, 13, 14, 15, 17, 20 and 21.\n",
    "\n",
    "For each of the 4 sub-datasets in C-MAPSS, the collected measurement data from each sensor are normalized to be within the range of [−1, 1] using the min-max normalization method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1.1  Time window processing\n",
    "In the multi-variate time series-based problems such as $RUL$ estimation, more information can be generally obtained from the temporal sequence data compared with the multi-variate data point sampled at a single time step. In this paper, a time window is adopted for the data preparation to use the multi-variate temporal information. Let $N_{tw}$ denote the size of the time window. At each time step, all the past sensor data within the time window for each  engine unit are collected to form a high-dimensional feature vector, and used as the inputs for the network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Time window details**\n",
    "- $N_{tw} = 30$ \n",
    "- Stride = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1.2  R early\n",
    "In general, the engine unit works normally in the early age and degrades afterwards. It is assumed to have a constant RUL label in the initial period. Following the recent researches in the literature [2,5,42] , $R_{early}$ which is a constant RUL value, is used as the target labels for the data points in the early period. It should be noted that $R_{early}$ has noticeable effect on the prognostic performance on the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window(data, N_tw = 30, stride = 1):\n",
    "    N_en = np.unique(data[:,0]).shape[0]                            # Number of engines (N_en)\n",
    "    m = 0\n",
    "    for i in range(N_en):\n",
    "        n_H   = data[data[:,0] == i+1,0].shape[0]\n",
    "        N_sw  = int((n_H- N_tw) / stride + 1)                       # Number of sliding windows for engine 'i' \n",
    "        for h in range(N_sw):\n",
    "            m = m + 1    \n",
    "    return m, N_en        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(N_tw, stride, sel, R_early):\n",
    "    # Load training data\n",
    "    basepath        = path.dirname(os.getcwd()) \n",
    "    train_set       = np.loadtxt(path.abspath(path.join(basepath, \"data\", \"train_FD001.txt\")))  # Training set\n",
    "    train_set_x_org = train_set[:,sel]                              # Training set input space (x)    \n",
    "    train_set_c     = train_set[:,np.array([1])]                    # Training set cycles (c)\n",
    "    \n",
    "    # Normalize the data\n",
    "    ub = train_set_x_org.max(0)\n",
    "    lb = train_set_x_org.min(0)    \n",
    "    train_set_x = 2 * (train_set_x_org - lb) / (ub - lb) - 1   \n",
    "   \n",
    "    N_ft    = sel.shape[0]                                           # Nunber of features (N_ft)\n",
    "    m, N_en = sliding_window(train_set, N_tw, stride)                # Number of training data & engines\n",
    "    \n",
    "    train_x = np.empty((m, N_tw, N_ft, 1), float)\n",
    "    train_y = np.empty((m, 1), float)\n",
    "    \n",
    "    k = 0\n",
    "    for i in range(N_en):\n",
    "        idx       = train_set[:,0] == i+1                            # Index for engine number 'i'\n",
    "        train_i_x = train_set_x[idx,:]                               # Engine 'i' training  data\n",
    "        train_i_c = train_set_c[idx]                                 # Engine 'i' cycles (c)\n",
    "        train_i_y = train_i_c[-1] - train_i_c                        # RUL: Remaining Useful Lifetime for engine 'i'\n",
    "        train_i_y[train_i_y > R_early] = R_early                     # R_early = 125\n",
    "        N_sw      = int((train_i_x.shape[0] - N_tw) / stride + 1)    # Number of sliding windows for engine 'i' \n",
    "        for h in range(N_sw):\n",
    "            k = k + 1\n",
    "            vert_start = h * stride\n",
    "            vert_end   = h * stride + N_tw\n",
    "            train_i_x_slice = train_i_x[vert_start:vert_end,:]       # Training input data for engine 'i' on time window 'h'\n",
    "            train_i_y_slice = train_i_y[vert_end-1,:]                # Training output data for engine 'i' on time window 'h'\n",
    "            train_i_x_slice.shape = (N_tw, N_ft, 1)                  # Reshape training set input (N_tw, N_ft, 1)\n",
    "            train_i_y_slice.shape = (1, 1)                           # Reshape training set output (1, 1)\n",
    "            train_x[k-1,:,:] = train_i_x_slice\n",
    "            train_y[k-1,:] = train_i_y_slice\n",
    "     \n",
    "    # Load test data\n",
    "    test_set       = np.loadtxt(path.abspath(path.join(basepath, \"data\", \"test_FD001.txt\")))\n",
    "    test_set_x_org = test_set[:,sel]                                 # Test set input space (x)\n",
    "    test_set_c     = test_set[:,np.array([1])]                       # Test set cycles (c)\n",
    "    test_y         = np.loadtxt(path.abspath(path.join(basepath, \"data\", \"RUL_FD001.txt\")))    # Test set RUL (c)\n",
    "    test_y.shape   = (test_y.shape[0], 1)\n",
    "    \n",
    "    # Normalize the data\n",
    "    test_set_x = 2 * (test_set_x_org - lb) / (ub - lb) - 1   \n",
    "    \n",
    "    m_ts, N_en_ts = sliding_window(test_set, N_tw, stride)           # Number of training data & engines\n",
    "    \n",
    "    test_x = np.empty((N_en_ts, N_tw, N_ft, 1), float)\n",
    "    \n",
    "    k = 0\n",
    "    for ii in range(N_en_ts):\n",
    "        engine         = test_set[:,0] == ii+1                       # Index for engine number 'i'\n",
    "        test_i_x       = test_set_x[engine,:]                        # Engine 'i' test  data\n",
    "        test_i_x_slice = test_i_x[-N_tw:,:]                          # Training input data for engine 'i' on time window 'h'\n",
    "        test_i_x_slice.shape = (N_tw, N_ft, 1)                       # Reshape training set input (N_tw, N_ft, 1)\n",
    "        test_x[ii,:,:] = test_i_x_slice\n",
    "    \n",
    "    return train_x, train_y, test_x, test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_tw     = 30                                                               # Time Window (N_tw)\n",
    "R_early  = 125                                                              # Max RUL in training set\n",
    "stride   = 1\n",
    "sel      = np.array([6, 7, 8, 11, 12, 13, 15, 16, 17, 18, 19, 21, 24, 25])  # Index of input features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training examples = 17731\n",
      "number of test examples = 100\n",
      "X_train shape: (17731, 30, 14, 1)\n",
      "Y_train shape: (17731, 1)\n",
      "X_test shape: (100, 30, 14, 1)\n",
      "Y_test shape: (100, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train, Y_train, X_test, Y_test = load_dataset(N_tw, stride, sel, R_early)\n",
    "print (\"number of training examples = \" + str(X_train.shape[0]))\n",
    "print (\"number of test examples = \" + str(X_test.shape[0]))\n",
    "print (\"X_train shape: \" + str(X_train.shape))\n",
    "print (\"Y_train shape: \" + str(Y_train.shape))\n",
    "print (\"X_test shape: \" + str(X_test.shape))\n",
    "print (\"Y_test shape: \" + str(Y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2  Network Structure\n",
    "\n",
    "In general, the proposed deep learning method consists of two sub-structures, i.e. multiple convolution neural networks and fully-connected layer for regression.\n",
    "\n",
    "First, the input data sample is prepared in 2-dimensional (2D) format. The dimension of the input is $N_{tw} × N_{ft}$, where $N_{tw}$ denotes the time sequence dimension and $N_{ft}$ is the number of selected features (i.e. number of sensor measurements).\n",
    "\n",
    "Next, 4 identical convolution layers are stacked in the network for feature extraction. The convolutions considers $F_N$ filters with kernel size $F_L × 1$. Zerospadding operation is implemented to keep the feature map dimension unchanged. Therefore, the obtained output feature maps dimension is $N_{tw} × N_{ft} × F_N$. We use another convolution layer with 1 filter to combine the previous feature maps to be a unique one. The filter size is $3 × 1$.\n",
    "\n",
    "Afterwards, the 2-dimensional feature map is flattened and connected with a fully-connected layer. Note that dropout technique is used on the last feature map, i.e. the flattened layer, to relieve overfitting. Finally, one neuron is attached at the end of the proposed network for $RUL$ estimation.\n",
    "\n",
    "**Model Hyperparameters:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kernel size\n",
    "kernels = [10, 10, 10, 10, 3]\n",
    "\n",
    "# Number of filters (channels)\n",
    "filters = [10, 10, 10, 10, 1]\n",
    "\n",
    "# Activation\n",
    "activ = 'tanh'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3  Model in Keras\n",
    "Keras uses a different convention with variable names than TensorFlow. In particular, rather than creating and assigning a new variable on each step of forward propagation such as X, Z1, A1, Z2, A2, etc. for the computations for the different layers, in Keras code each line above just reassigns X to a new value using X = .... In other words, during each step of forward propagation, we are just writing the latest value in the commputation into the same variable X. The only exception was X_input, which we kept separate and did not overwrite, since we needed it at the end to create the Keras model instance (model = Model(inputs = X_input, ...) above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN_2d(input_shape, filters, kernels, activ):\n",
    "    \"\"\"\n",
    "    Implementation of the 1D_CNN model.\n",
    "    \n",
    "    Arguments:\n",
    "    input_shape -- shape of the images of the dataset\n",
    "\n",
    "    Returns:\n",
    "    model -- a Model() instance in Keras\n",
    "    \"\"\"\n",
    "    \n",
    "    # Retrieve Filters & kernels\n",
    "    F0, F1, F2, F3, F4 = filters                 \n",
    "    K0, K1, K2, K3, K4 = kernels    \n",
    "      \n",
    "    # Define the input placeholder as a tensor with shape input_shape    \n",
    "    X_input = Input(input_shape)\n",
    "   \n",
    "    # CONV -> RELU Block applied to X_input\n",
    "    X = Conv2D(F0, (K0, 1), strides = (1, 1), padding = 'same', activation = activ, kernel_initializer = glorot_uniform(seed=0), name = 'conv0')(X_input)\n",
    "    \n",
    "    # CONV -> RELU Block applied to X\n",
    "    X = Conv2D(F1, (K1, 1), strides = (1, 1), padding = 'same', activation = activ, kernel_initializer = glorot_uniform(seed=0), name = 'conv1')(X)\n",
    "      \n",
    "    # CONV -> RELU Block applied to X\n",
    "    X = Conv2D(F2, (K2, 1), strides = (1, 1), padding = 'same', activation = activ, kernel_initializer = glorot_uniform(seed=0), name = 'conv2')(X)\n",
    "        \n",
    "    # CONV -> RELU Block applied to X\n",
    "    X = Conv2D(F3, (K3, 1), strides = (1, 1), padding = 'same', activation = activ, kernel_initializer = glorot_uniform(seed=0), name = 'conv3')(X)\n",
    "      \n",
    "    # CONV -> BN -> RELU Block applied to X\n",
    "    X = Conv2D(F4, (K4, 1), strides = (1, 1), padding = 'same', activation = activ, kernel_initializer = glorot_uniform(seed=0), name = 'conv4')(X)\n",
    "    \n",
    "    # FLATTEN X (means convert it to a vector) + FULLYCONNECTED\n",
    "    X = Flatten()(X)\n",
    "    X = Dropout(0.5)(X)\n",
    "    X = Dense(100, activation = activ, name='fc')(X)\n",
    "    X = Dense(1, name='RUL')(X)\n",
    "\n",
    "    # Create model. This creates your Keras model instance, you'll use this instance to train/test the model.\n",
    "    model = Model(inputs = X_input, outputs = X, name='CNN_2d')    \n",
    "   \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we feed the model hyperparameters to the CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the model\n",
    "CNN_2d = CNN_2d(X_train.shape[1:],filters, kernels, activ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 30, 14, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv0 (Conv2D)               (None, 30, 14, 10)        110       \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 30, 14, 10)        1010      \n",
      "_________________________________________________________________\n",
      "conv2 (Conv2D)               (None, 30, 14, 10)        1010      \n",
      "_________________________________________________________________\n",
      "conv3 (Conv2D)               (None, 30, 14, 10)        1010      \n",
      "_________________________________________________________________\n",
      "conv4 (Conv2D)               (None, 30, 14, 1)         31        \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 420)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 420)               0         \n",
      "_________________________________________________________________\n",
      "fc (Dense)                   (None, 100)               42100     \n",
      "_________________________________________________________________\n",
      "RUL (Dense)                  (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 45,372\n",
      "Trainable params: 45,372\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "CNN_2d.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Model Training\n",
    "\n",
    "Its configuration is determined including the number of hidden layers, convolution filter number and length etc. The DCNN takes as the inputs the normalized training data, and the labeled RUL values for the training samples are used as the target outputs of the network\n",
    "\n",
    "All the layers use tanh as the activation functions, and Xavier normal initializer is employed for the weight initializations [38]. Back-propagation learning is used for the updates of the weights in the network. The Adam optimization algorithm [40] is used with mini-batches for the updates. For each training epoch, the samples are randomly divided into multiple mini-batches with each batch containing 512 samples, and put into the training system. Next, the network information, i.e. the weights in each layer, are optimized based on the mean loss function of each mini-batch. It should be noted that the selection of batch size affects the network training performance [45]. The batch size of 512 samples is found appropriate based on the experiments and it is used in all the case studies in this paper. In addition, varying learning rate is adopted. For the first 200 epochs from the beginning, the learning rate is 0.001 for fast optimization. The learning rate of 0.0001 is used afterwards for stable convergence. The maximum number of the training epochs is 250."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train and test this model, there are four steps in Keras:\n",
    "1. Create the model by calling the function above\n",
    "2. Compile the model by calling `model.compile(optimizer = \"...\", loss = \"...\")`\n",
    "3. Train the model on train data by calling `model.fit(x = ..., y = ..., epochs = ..., batch_size = ...)`\n",
    "4. Test the model on test data by calling `model.evaluate(x = ..., y = ...)`\n",
    "\n",
    "If you want to know more about `model.compile()`, `model.fit()`, `model.evaluate()` and their arguments, refer to the official [Keras documentation](https://keras.io/models/model/).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_2d.compile(optimizer = \"Adam\", loss = \"mean_squared_error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Learning rate:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Rate: 0.001\n"
     ]
    }
   ],
   "source": [
    "print('Learning Rate: ' + str(K.get_value(CNN_2d.optimizer.lr)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define an updatable plot to track training evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# updatable plot\n",
    "class PlotLosses(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.i = 0\n",
    "        self.x = []\n",
    "        self.losses = []\n",
    "        self.val_losses = []        \n",
    "        self.fig = plt.figure()        \n",
    "        self.logs = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):        \n",
    "        self.logs.append(logs)\n",
    "        self.x.append(self.i)\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        self.val_losses.append(logs.get('val_loss'))\n",
    "        self.i += 1\n",
    "        \n",
    "        clear_output(wait=True)\n",
    "        #fig, ax1 = plt.subplots()\n",
    "        #ax1.plot(self.x, self.losses, label=\"loss\", color='tab:blue')\n",
    "        #ax1.set_xlabel('epoch')\n",
    "        #ax1.set_ylabel('loss', color='tab:blue')\n",
    "        #ax1.tick_params('y', colors='tab:blue')\n",
    "        #ax2 = ax1.twinx()\n",
    "        #ax2.plot(self.x, self.val_losses, label=\"val_loss\", color='tab:orange')\n",
    "        #ax2.set_ylabel('val_loss', color='tab:orange')\n",
    "        #ax2.tick_params('y', colors='tab:orange')\n",
    "        plt.plot(self.x, np.sqrt(self.losses), label=\"loss\")\n",
    "        plt.plot(self.x, np.sqrt(self.val_losses), label=\"val_loss\")\n",
    "        plt.ylabel('loss - RMSE')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['train','test'], loc='upper left')\n",
    "        plt.title('model loss')\n",
    "        #fig.tight_layout()\n",
    "        plt.show();\n",
    "        \n",
    "plot_losses = PlotLosses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11b537390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17731/17731 [==============================] - 17s 975us/step - loss: 3733.2919 - val_loss: 3147.3113\n",
      "Epoch 8/200\n",
      " 4096/17731 [=====>........................] - ETA: 14s - loss: 3508.2011"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-de2443957264>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mCNN_2d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mplot_losses\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/snn/anaconda/envs/tensorflow/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1629\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1630\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1631\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1632\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1633\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/Users/snn/anaconda/envs/tensorflow/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1211\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1214\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/snn/anaconda/envs/tensorflow/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2330\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2331\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2332\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2333\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/snn/anaconda/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/snn/anaconda/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/snn/anaconda/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/Users/snn/anaconda/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/snn/anaconda/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "CNN_2d.fit(X_train, Y_train, epochs = 200, batch_size = 512, validation_data = (X_test, Y_test), callbacks=[plot_losses])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.set_value(CNN_2d.optimizer.lr,0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_2d.fit(X_train, Y_train, epochs = 50, batch_size = 512, validation_data = (X_test, Y_test), callbacks=[plot_losses])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Learning rate:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Learning Rate: ' + str(K.get_value(CNN_2d.optimizer.lr)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the model (architecture, weights, ...) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_2d.save('CNN_v5_tanh_v2_0.50_HL_4x10_1.h5') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Experimental Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Performance Metrics\n",
    "In this study, 2 metrics have been used for evaluating the performance of the proposed prognostic method, i.e. scoring function and root mean square error.\n",
    "\n",
    "The scoring function used in this study has been proposed by many researchers [2, 43, 44] and also employed by the International Conference on Prognostics and Health Management Data Challenge. \n",
    "\n",
    "where s denotes the score and N is the total number of testing data samples. di = RUL - RULi, that is the error between the estimated RUL value and the actual RUL value for the i-th testing data sample. The scoring function penalizes late prediction more than early prediction, that is because late prediction usually leads to more severe consequences in many\n",
    "fields such as aerospace industries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_cal(y_hat, Y_test):\n",
    "    d   = y_hat - Y_test\n",
    "    tmp = np.zeros(d.shape[0])\n",
    "    for i in range(d.shape[0]):\n",
    "        if d[i,0] >= 0:\n",
    "           tmp[i] = np.exp( d[i,0]/10) - 1\n",
    "        else:\n",
    "           tmp[i] = np.exp(-d[i,0]/13) - 1\n",
    "    return tmp "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another popular metric to evaluate the effectiveness of the proposed method is Root Mean Square Error (RMSE)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 4.2 Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = CNN_2d.evaluate(x = X_train, y = Y_train)\n",
    "print()\n",
    "print (\"Test  MSE = \" + str(preds))\n",
    "print (\"Test RMSE = \" + str(np.sqrt(preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_tr   = CNN_2d.predict(x = X_train)\n",
    "score_i_tr = score_cal(y_hat_tr, Y_train)\n",
    "score_tr   = print(\"Score = \" + str(sum(score_i_tr)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.1 Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_tr = y_hat_tr - Y_train\n",
    "plt.hist(d_tr, bins='auto')  \n",
    "plt.title('Error distribution - Training Set')\n",
    "plt.ylabel('f')\n",
    "plt.xlabel(\"Error: $RUL_{hat}$ - RUL\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 4.3 Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat   = CNN_2d.predict(x = X_test)\n",
    "score_i = score_cal(y_hat, Y_test)\n",
    "score   = print(\"Score = \" + str(sum(score_i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = CNN_2d.evaluate(x = X_test, y = Y_test)\n",
    "print()\n",
    "print (\"MSE = \" + str(preds))\n",
    "print (\"RMSE = \" + str(np.sqrt(preds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.1 Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = y_hat - Y_test\n",
    "plt.hist(d, bins='auto')  \n",
    "plt.title('Error distribution - Test Set')\n",
    "plt.ylabel('f')\n",
    "plt.xlabel(\"Error: $RUL_{hat}$ - RUL\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x     = range(0,100)\n",
    "y_ts  = np.sort(Y_test[:,0])\n",
    "idx   = np.argsort(Y_test[:,0])\n",
    "y_tr  = y_hat[idx,0]\n",
    "plt.plot(x, y_tr, 'bo-', x, y_ts, 'ro-')\n",
    "plt.title('RUL vs. engine #')\n",
    "plt.ylabel('RUL')\n",
    "plt.xlabel('engine #')\n",
    "plt.legend(['Prediction', 'Target'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(Y_test, y_hat, 'bo')\n",
    "plt.title('RUL vs. RUL #')\n",
    "plt.ylabel('RUL Estimated')\n",
    "plt.xlabel('RUL True')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test[Y_test > R_early] = R_early                     # R_early = 125 \n",
    "preds = CNN_2d.evaluate(x = X_test, y = Y_test)\n",
    "print()\n",
    "print (\"MSE = \" + str(preds))\n",
    "print (\"RMSE = \" + str(np.sqrt(preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x     = range(0,100)\n",
    "y_ts  = np.sort(Y_test[:,0])\n",
    "idx   = np.argsort(Y_test[:,0])\n",
    "y_tr  = y_hat[idx,0]\n",
    "plt.plot(x, y_tr, 'bo-', x, y_ts, 'ro-')\n",
    "plt.title('RUL vs. engine #')\n",
    "plt.ylabel('RUL')\n",
    "plt.xlabel('engine #')\n",
    "plt.legend(['Prediction', 'Target'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(Y_test, y_hat, 'bo')\n",
    "plt.plot(Y_test,Y_test, 'r-')\n",
    "plt.plot(Y_test,Y_test+20, 'r--')\n",
    "plt.plot(Y_test,Y_test-20, 'r--')\n",
    "plt.title('RUL vs. RUL #')\n",
    "plt.ylabel('RUL Estimated')\n",
    "plt.xlabel('RUL True')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
